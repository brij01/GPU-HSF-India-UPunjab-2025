{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183ff73e",
   "metadata": {},
   "source": [
    "> **Reference:**\n",
    "> Celeritas project: [https://github.com/celeritas-project/celeritas](https://github.com/celeritas-project/celeritas)\n",
    "> Geometry & macros: [https://github.com/celeritas-project/atlas-tilecal-integration](https://github.com/celeritas-project/atlas-tilecal-integration)\n",
    "> Official releases: [https://github.com/celeritas-project/celeritas/releases](https://github.com/celeritas-project/celeritas/releases)\n",
    ">\n",
    "> **Hardware:** Linux/WSL2 + CUDA 11/12 GPU (compute 6.0+). CPU-only fallback included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a48d0",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Geant4 Simulation of the ATLAS Tile Calorimeter\n",
    "\n",
    "This self-contained notebook guides you through building and running a **CUDA-enabled Geant4 + DD4hep + Celeritas** stack, loading a realistic slice of the ATLAS Tile Calorimeter, and benchmarking CPU vs GPU performance. It is designed as a ~40-minute hands-on exercise for HEP newcomers and advanced users alike.\n",
    "\n",
    "**Learning objectives**\n",
    "\n",
    "* Install required software inside the notebook (Conda optional)\n",
    "* Fetch detector geometry from DD4hep\n",
    "* Compile a minimal C++ application off-loading electromagnetic transport to the GPU\n",
    "* Time simulations on CPU and GPU and visualise energy-deposit spectra\n",
    "* Complete two short exercises with provided solution templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4d442",
   "metadata": {},
   "source": [
    "## 0  Environment bootstrap (optional)\n",
    "If you do **not** already have a Python ≥3.11 Conda environment, run the commented commands below in a terminal to create one named `tilegpu` and start JupyterLab.\n",
    "\n",
    "```bash\n",
    "# conda create -n tilegpu -c conda-forge python=3.11 jupyterlab\n",
    "# conda activate tilegpu\n",
    "# jupyter lab\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01a0ab",
   "metadata": {},
   "source": [
    "## Official Celeritas Installation (Spack)\n",
    "\n",
    "To install Celeritas and its dependencies, use Spack as follows:\n",
    "\n",
    "```bash\n",
    "# Install Spack\n",
    "git clone --depth=2 https://github.com/spack/spack.git\n",
    ". spack/share/spack/setup-env.sh\n",
    "\n",
    "# Set up CUDA (if you have a GPU)\n",
    "spack external find cuda\n",
    "\n",
    "# Set default configuration (replace cuda_arch=80 with your GPU architecture)\n",
    "spack config add packages:all:variants:\"cxxstd=17 +cuda cuda_arch=80\"\n",
    "\n",
    "# Install Celeritas\n",
    "spack install celeritas\n",
    "spack load celeritas\n",
    "```\n",
    "\n",
    "See the [Celeritas documentation](https://github.com/celeritas-project/celeritas) for more details and integration steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lightweight Python deps (≈1 min on first run)\n",
    "%pip install --quiet cupy-cuda12x uproot awkward matplotlib nbformat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f8e22",
   "metadata": {},
   "source": [
    "### Why Celeritas + DD4hep?\n",
    "* **Celeritas** accelerates Geant4 electromagnetic (e±/γ) transport on NVIDIA GPUs, yielding order-of-magnitude speed-ups for calorimeter studies.\n",
    "* **DD4hep** supplies experiment-quality detector descriptions; the TileCal GDML used here is taken from the public ATLAS repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Note:**\n",
    "\n",
    "Celeritas and Geant4 should be installed and loaded using Spack as described above. Do not use pre-built bundles. After installation, you can use the libraries and executables provided by Spack.\n",
    "\n",
    "See the [Celeritas documentation](https://github.com/celeritas-project/celeritas) for integration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9120cc",
   "metadata": {},
   "source": [
    "## 1  Prepare ATLAS TileCal Geometry and Macro\n",
    "The next cell downloads a small Tile Calorimeter GDML plus a steering macro that shoots **10 GeV electrons** along the beam axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, pathlib, os\n",
    "\n",
    "files = {\n",
    "    \"TileTB_2B1EB_nobeamline.gdml\": \"https://raw.githubusercontent.com/celeritas-project/atlas-tilecal-integration/main/TileTB_2B1EB_nobeamline.gdml\",\n",
    "    \"TBrun_elec.mac\": \"https://raw.githubusercontent.com/celeritas-project/atlas-tilecal-integration/main/TBrun_elec.mac\"\n",
    "}\n",
    "for fname, url in files.items():\n",
    "    if not pathlib.Path(fname).exists():\n",
    "        print(f\"Downloading {fname} …\")\n",
    "        urllib.request.urlretrieve(url, fname)\n",
    "    else:\n",
    "        print(f\"{fname} already present\")\n",
    "print(\"Geometry & macro ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04f308",
   "metadata": {},
   "source": [
    "## 2  Minimal Geant4 + Celeritas Off-load Application\n",
    "Below we write **<60 lines** of C++ that\n",
    "1. Build a multithreaded Geant4 run manager\n",
    "2. Load the TileCal geometry with DD4hep\n",
    "3. Insert *Celeritas* as the parallel GPU transport\n",
    "4. Execute the macro to shoot particles\n",
    "\n",
    "> **Tip:** Compiling inside Jupyter uses the system compiler via shell commands starting with `!`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6416a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tile_gpu.cc\n",
    "#include <G4RunManagerFactory.hh>\n",
    "#include <G4UImanager.hh>\n",
    "#include <FTFP_BERT.hh>\n",
    "#include <DDG4/Geant4DetectorConstruction.h>\n",
    "#include <celeritas/TrackingManagerConstructor.hh>\n",
    "\n",
    "int main()\n",
    "{\n",
    "    auto rm = G4RunManagerFactory::CreateRunManager(G4RunManagerType::MT);\n",
    "    rm->SetUserInitialization(new dd4hep::sim::Geant4DetectorConstruction(\"TileTB_2B1EB_nobeamline.gdml\"));\n",
    "\n",
    "    auto* phys = new FTFP_BERT;\n",
    "    phys->RegisterPhysics(new celeritas::TrackingManagerConstructor);\n",
    "    rm->SetUserInitialization(phys);\n",
    "\n",
    "    rm->Initialize();\n",
    "\n",
    "    auto* ui = G4UImanager::GetUIpointer();\n",
    "    ui->ApplyCommand(\"/tracking/verbose 0\");\n",
    "    ui->ApplyCommand(\"/control/execute TBrun_elec.mac\");\n",
    "\n",
    "    delete rm;\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2197c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the application\n",
    "!g++ tile_gpu.cc -std=c++20 -O3 $(geant4-config --cflags --libs) -I$CELER_DIR/include -L$CELER_DIR/lib -lCeleritas -o tile_gpu\n",
    "print(\"Compilation finished → executable ./tile_gpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62676185",
   "metadata": {},
   "source": [
    "## 3  Benchmark CPU vs GPU\n",
    "We run the application twice: first forcing Celeritas off (CPU-only) then on (GPU). The helper function toggles this via the environment variable `CELER_DISABLE_DEVICE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, time, os, re\n",
    "\n",
    "def run_tile(use_gpu: bool = True):\n",
    "    env = os.environ.copy()\n",
    "    env[\"CELER_DISABLE_DEVICE\"] = \"0\" if use_gpu else \"1\"\n",
    "    start = time.time()\n",
    "    output = subprocess.check_output([\"./tile_gpu\"], text=True, env=env)\n",
    "    dt = time.time() - start\n",
    "    m = re.search(r\"Run summary: *(\\d+) events\", output)\n",
    "    nev = int(m.group(1)) if m else 1000\n",
    "    return dt, nev\n",
    "\n",
    "cpu_t, nevt = run_tile(False)\n",
    "gpu_t, _ = run_tile(True)\n",
    "print(f\"Simulated {nevt} events\n",
    "CPU time : {cpu_t:.2f} s\n",
    "GPU time : {gpu_t:.2f} s\n",
    "Speed-up  : ×{cpu_t/gpu_t:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ef320",
   "metadata": {},
   "source": [
    "## 4  Visualise Energy Deposits\n",
    "The Geant4 scorer writes ROOT output; we open it with `uproot` and build a log-scale histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f52e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, awkward as ak, uproot, pathlib\n",
    "\n",
    "root_file = next(pathlib.Path('.').glob('*.root'))\n",
    "print('Reading', root_file)\n",
    "file = uproot.open(str(root_file))\n",
    "edep = file[\"TileCellHits/Edep\"].array()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(edep.to_numpy(), bins=120, log=True, histtype='step')\n",
    "plt.xlabel('Energy deposit per hit [MeV]')\n",
    "plt.ylabel('Counts / bin')\n",
    "plt.title('10 GeV e⁻ energy deposits (GPU offload)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a856017",
   "metadata": {},
   "source": [
    "## 5  Exercises (≈15 min)\n",
    "\n",
    "### Exercise 1 – Hadron shower\n",
    "Modify **`TBrun_elec.mac`** to shoot **30 GeV π⁺** instead of electrons and repeat the timing study. Observe that GPU advantage decreases because sizeable hadronic cascades still track on the CPU.\n",
    "\n",
    "### Exercise 2 – Absorber thickness scan\n",
    "1. Use the (mock) macro command `/dd/geometry/scaleAbsorber X cm` where *X*=1–5 cm.\n",
    "2. Loop over thicknesses, recording (a) total visible energy and (b) GPU speed-up.\n",
    "3. Plot both on dual y-axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— Solution scaffolding ——\n",
    "import json, numpy as np\n",
    "\n",
    "def run_with_macro(macro_text):\n",
    "    macro_path = 'tmp.mac'\n",
    "    with open(macro_path,'w') as f:\n",
    "        f.write(macro_text)\n",
    "    env = os.environ.copy()\n",
    "    env[\"CELER_DISABLE_DEVICE\"] = \"1\"\n",
    "    subprocess.check_output([\"./tile_gpu\"], env=env, text=True)\n",
    "    os.remove(macro_path)\n",
    "    # add return values extraction if needed\n",
    "\n",
    "# Students fill in details based on above helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc1ac8",
   "metadata": {},
   "source": [
    "## 6  Clean-up\n",
    "Run the following to delete binaries and large archives when finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81da5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf geant4_celeritas_cuda12.tgz geant4_cuda *.root tile_gpu tile_gpu.cc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "array-oriented-programming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
